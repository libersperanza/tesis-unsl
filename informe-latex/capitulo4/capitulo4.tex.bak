\chapter{Soporte externo factual: una m\'etrica de calidad para Wikipedia}

En el cap\'itulo anterior, se describieron diferentes enfoques computacionales para estudiar la calidad de los art\'iculos en Wikipedia, as\'i como tambi\'en, se aclararon las tareas de \emph{defnici\'on de m\'etrica de calidad} \emph{identificaci\'on de art\'iculos destacados} y \emph{detecci\'on de fallas de calidad} en los mismos. Adem\'as, se explicaron caracter\'isticas relacionadas a \emph{medidas}, \emph{m\'etricas de calidad} y sus diferencias.

En el siguiente cap\'itulo se detallar\'a el m\'etodo propuesto para determinar el \emph{soporte externo factual (SEF)} de un documento de Wikipedia en Ingl\'es y c\'omo fue alcanzado. Se mostrar\'an los tipos de archivos y colecciones utilizadas as\'i como tambi\'en diferentes herramientas que estuvieron involucradas y sirvieron para tareas espec\'ificas, como el \emph{lematizador} y el \emph{sistema de extracci\'on abierta}.

Por otra parte, se detallar\'an c\'alculos y ejecuci\'ones necesarias que permitieron la creaci\'on de \emph{medidas de soporte} que sirvieron para determinar cuanta informaci\'on de un documento existe en una fuente externa, permitiendo verificar cuan ver\'idica o bien conocida es dicha informaci\'on.

Por \'ultimo, tambi\'en, se explicar\'an los mecanismos de matching, es decir, como se comparaba la informaci\'on que se buscaba con la que exist\'ia como fuente de conocimiento.

\emph{Organizaci\'on del cap\'itulo.} La subsecci\'on 4.1 presenta las colecciones y tipos de archivos utilizados junto con las caracter\'isticas propias de cada uno de ellos. La subsecci\'on 4.2, se enfoca en mostrar como fueron modificados y preparados los archivos sobre los que se trabaj\'o, con el fin de que todos mantuvieran una estructura homog\'enea y fueran identificados m\'as facilmente. La subsecci\'on 4.3 describe c\'omo y cuando se utiliz\'o el lematizador. La subsecci\'on 4.4 introduce los sistemas de extracci\'on abierta y hace hincapi\'e en Reverb, sistema de extracci\'on utilizado en este trabajo. La subsecci\'on 4.5 detalla las medidas de soporte creadas, las cuales tienen como prop\'osito determinar cuan ver\'idica es la informaci\'on. La subsecci\'on 4.6 muestra los diferentes tipos de matching utilizados en este trabajo y como se hace la comparaci\'on entre los datos existentes y los que se encuentran en los documentos de Wikipedia, es decir, sobre los que se desea comprobar su soporte o existencia.

\section{Tipos de archivos y colecciones utilizadas}

En este trabajo se utiliz\'o una colecci\'on suministrada por el Workshop PAN como se mencion\'o en el cap\'itulo anterior y diferentes tipos de archivos, sobre los cuales se realizaron diversos c\'alculos. A continuaci\'on se detalla cada tipo de archivo y su utilidad para que estos puedan ser diferenciados entre s\'i.

\begin{itemize}

\item	\emph{Archivos de Texto Plano:} es el nombre que se le asocia a los archivos de una colecci\'on de documentos, en la que cada una de las p\'aginas seleccionadas de Wikipedia para esta colecci\'on, es representada a trav\'es de un archivo con su texto puro, plano, es decir, que s\'olo incluye caracteres de c\'odigo ASCII\footnote{C\'odigo ASCII. https://es.wikipedia.org/wiki/ASCII}. De ahora en adelante ser\'an nombrados como ATP.

\item	\emph{Archivos con hechos:} es el nombre que se le otorga a los archivos que se generan a partir de los ATP. Cada archivo generado contiene todos los hechos encontrados por la herramienta ReVerb\footnote{Herramienta de Extracci\'on Abierta de Informaci\'on. http://reverb.cs.washington.edu/} , herramienta que autom\'aticamente identifica y extrae relaciones binarias de sentencias escritas en ingl\'es. Cabe aclarar que el tamaño de estos archivos depende exclusivamente de la cantidad de hechos encontrados. De ahora en adelante ser\'an nombrados como AH.
Originalmente, cada archivo AH cuenta con los siguientes campos:

\begin{itemize}
\item	El texto ``extraction'', representa la extracci\'on de un hecho encontrado.
\item	La ruta donde se encuentra el ATP del cual se extraen los hechos.
\item	El n\'umero de sentencia de la cual se extrajo el hecho.
\item	El argumento 1 (sujeto de la oraci\'on), que corresponde a un conjunto de palabras separadas por espacios.
\item	La relaci\'on (predicado de la oraci\'on), que corresponde a un conjunto de palabras separadas por espacios en la cual se encuentra al menos un verbo.
\item	El argumento 2, que corresponde a un conjunto de palabras separadas por espacios.
\item	El nivel de confianza con el que el hecho fue extra\'ido. Un valor num\'erico que representa cuan “correcta” fue dicha extracci\'on, seg\'un ~\cite{AnStOr:11}.
\end{itemize}

\item	\emph{Archivos con trigramas:} a trav\'es de la lectura de cada uno de los ATP, se genera su archivo correspondiente de trigramas, que equivale a una lista de todos los trigramas encontrados, ubicados cada uno en un rengl\'on del archivo. De ahora en adelante ser\'an nombrados como ATRI.

\item	\emph{Fuente externa:} el recurso externo utilizado como base de conocimiento de 2.69Gb de tamaño en disco, desde ahora llamada FE, corresponde a un \'unico archivo de texto plano codificado en UTF-8 que contiene registros en forma de tuplas contra los cuales se contrastan los registros pertenecientes a los AH.
Actualmente este subconjunto cuenta con aproximadamente 15 millones de hechos tomados directamente de la Web\footnote{Disponible para la descarga desde: http://reverb.cs.washington.edu/}\footnote{Detalles y aclaraciones del archivo.  http://reverb.cs.washington.edu/README\_data.txt}.
Creado por Anthony Fader, Michael Schmitz, Robert Bart, Stephen Soderland y Oren Etzioni, la FE es un subconjunto de datos correspondiente a la salida de la ejecuci\'on de ReVerb sobre la secci\'on en Ingl\'es del Corpus ClueWeb09\footnote{Disponible para la descarga desde: http://lemurproject.org/clueweb09/}, el cual consiste de 1 bill\'on de p\'aginas Web en 10 lenguajes diferentes que fueron recopiladas entre enero y febrero de 2009.
Para obtener un conjunto pequeño, distribuible a trav\'es de la Web y de alta precisi\'on, se aplicaron filtros sobre las extracciones de la siguiente manera:

\begin{itemize}
\item	\emph{Umbral de Confianza:} a cada par (extracci\'on, sentencia) se le asign\'o un puntaje entre 0 y 1 a trav\'es de un clasificador ~\cite{AnStOr:11}. Luego, se eliminaron todas las extracciones con nivel de confianza menor que 0.9.

\item	\emph{Filtro Sint\'actico:} se filtr\'o toda extracci\'on cuyos argumentos son nombres comunes definidos (\emph{NN} representando sustantivos singulares o \emph{NNS} representando sustantivos plurales), o contienen pronombres, determinantes demostrativos y ciertos cuantificadores (both, all, certain, other, etc.). Tambi\'en se filtraron extracciones que conten\'ian nombres propios o n\'umeros en sus relaciones.

\item	\emph{Palabras de Paro:} se eliminaron las extracciones que conten\'ian palabras temporales comunes (yesterday, tonight, days of the week, etc.) y tambi\'en aquellas con relaciones que eran desinformativas (have, said, etc.).

\item	\emph{Umbral de la frecuencia de la cadena:} se cont\'o el n\'umero de extracciones diferentes en la que cada argumento y relaci\'on aparec\'ia y luego se filtr\'o cualquier extracci\'on (x,r,y) con (freq(x) < 5) o (freq(r) < 5) o (freq(y) < 5).
\end{itemize}

Luego de la aplicaci\'on de estos filtros, se aplicaron normalizaciones morfol\'ogicas a los argumentos y relaciones mediante la eliminaci\'on de pluralizaciones y capitalizaciones, entre otras. Por \'ultimo se unificaron las extracciones que ten\'ian la misma forma normalizada.

El formato original del archivo contiene las siguientes columnas:

\begin{itemize}
\item	Id de Extracci\'on.
\item	Argumento 1.
\item	Relaci\'on.
\item	Argumento 2.
\item	Argumento 1 - normalizado.
\item	Relaci\'on - normalizada.
\item	Argumento 2 - normalizado.
\item	El n\'umero de sentencias diferentes de la que la sentencia fue extra\'ida.
\item	El m\'aximo puntaje de nivel de confianza asignado a esa extracci\'on, sobre todas las sentencias de la cual fue extra\'ida.
\item	Lista de URLs (separadas por "|") para cada sentencia.
\end{itemize}

\end{itemize}

\section{Preparaci\'on de los archivos}
Previamente a las ejecuciones que calculan las medidas de soporte, se generaron scripts y diferentes versiones de sistemas para preparar los archivos con los que se iba a trabajar.
En primer lugar, se modificaron los ATP, luego los AH y por \'ultimo los ATRI con el fin de normalizarlos, tener mejor referencia a ellos en las diferentes colecciones y adaptarlos mejorando as\'i la eficiencia.
El nombre que se le asign\'o a los archivos cumple con la siguiente regla:

En primer lugar el nombre de la colecci\'on:

\begin{itemize}
\item	FA (Featured Article)
\item	NF (No Featured Article)
\item	OR (Original Research)	
\end{itemize}

En segundo lugar y consecutivamente, un valor num\'erico que ordena la cantidad de archivos origin\'andose desde 0 hasta la cantidad de archivos totales menos uno de esa colecci\'on.
Por \'ultimo, se anex\'o al texto anterior el tipo de archivo que se trabaja:

\begin{itemize}
\item	\_texto\_plano (Archivo de texto plano).
\item	\_reverb (Archivo con los hechos extra\'idos de los textos planos).
\item	\_trigramas (Trigramas relacionados y extra\'idos de los textos planos).
\end{itemize}

A continuaci\'on, veamos algunos ejemplos de los nombres finales de los archivos:

\begin{itemize}
\item	FA0\_texto\_plano (Archivo n\'umero 0 de texto plano).
\item	NF5\_reverb (Archivo n\'umero 5 con los hechos extra\'idos de los textos planos).
\item	OR10\_trigramas (Archivo n\'umero 10 de trigramas relacionados y extra\'idos de los textos planos).
\end{itemize}

Las referencias internas correspondientes a las rutas de los archivos que contienen los hechos extra\'idos por ReVerb tambi\'en fueron modificadas con el mismo nombre y mecanismo.
Tambi\'en se filtr\'o la cantidad de datos disponibles en dichos archivos para manejar solo el conjunto de datos necesario. Cada l\'inea del archivo que contiene los hechos extra\'idos por ReVerb representa un registro. Entre los campos disponibles de estos registros quedaron seleccionados los siguientes:

\begin{itemize}
\item	Direcci\'on de donde se alojaba el archivo de texto plano del cual se extrajeron originalmente los hechos.
\item	Argumento 1, palabras separadas por espacios en blanco.
\item	Relaci\'on, palabras separadas por espacios en blanco en la cual se encuentra al menos un verbo.
\item	Argumento 2, palabras separadas por espacios en blanco.
\item	El nivel de confianza con el que el hecho fue extra\'ido. Denota la confianza en la correctitud de la extracci\'on, mayor es el n\'umero, m\'as digno de confianza es el hecho.
\end{itemize}

A la FE tambi\'en se le redujeron la cantidad de datos disponibles para cada registro, entre los cuales hallamos:

\begin{itemize}
\item	Argumento 1, palabras separadas por espacios en blanco.
\item	Relaci\'on, palabras separadas por espacios en blanco en la cual se encuentra al menos un verbo.
\item	Argumento 2, palabras separadas por espacios en blanco.
\item	La m\'axima puntuaci\'on de confianza asignada a este hecho sobre todas las sentencias de la cual fue extra\'ida.
\end{itemize}

Por otra parte, tambi\'en se generaron mecanismos para obtener la cantidad de sentencias de cada uno de los ATP, para principalmente, obtener la densidad factual de cada una de las sentencias ~\cite{LeVoErFeCaHoGrr:12}.

Luego de finalizar el trabajo anterior, se continu\'o con tareas que involucraron la modificaci\'on directa de los datos propiamente dichos de cada uno de los registros nombrados, tanto para los que se encontraban en los AH, como para los que se encontraban en la FE.

Para el primero de los casos, y para las diferentes versiones, se gener\'o una versi\'on en Java que, para cada uno de los registros pertenecientes a cada uno de los archivos de cada una de las colecciones, lematizaba y filtraba ciertas palabras. En particular, para el argumento 1 y 2 correspondiente a cada hecho, se lematizaron las palabras contenidas y adem\'as se eliminaron todas aquellas que no eran ni sustantivos, ni verbos, ni adjetivos, ni n\'umeros cardinales,  mientras que para la relaci\'on solo se realiz\'o la primera tarea nombrada.
En el segundo caso, para la FE, se procedi\'o de una manera diferente, ya que en una primera instancia se contaba con la relaci\'on y los dos argumentos lematizados, los cuales directamente fueron utilizados sin realizarles cambios. Sin embargo, se aplicaron m\'etodos para la eliminaci\'on de art\'iculos y preposiciones compuestas de hasta tres palabras, solo si se encontraban al principio o al final de los argumentos o la relaci\'on.

\section{Lematizador}
Originalmente, cada uno de los registros de los AH conten\'ia texto puro, como se hallaban en los ATP de donde fueron extra\'idos. Por lo cual, se pod\'ian encontrar palabras conjugadas y sin conjugar, en femenino y masculino, en singular y plural. Para normalizar todas estas variantes de palabras, se utiliz\'o un lematizador.

La lematizaci\'on, una tarea propia de la lingü\'istica computacional ampliamente utilizada en herramientas vinculadas al Procesamiento del Lenguaje Natural y extractores de informaci\'on, consiste en, dada una forma flexionada de una palabra (femenino, plural, conjugada, etc.) encontrar su lema correspondiente, es decir, una unidad representante de todas las palabras flexionadas de una misma palabra.

La herramienta utilizada se llama CICWN\footnote{CICWN: Viveros-Jim\'enez, F., Gelbukh, A., Sidorov, G.: Improving Simplified Lesk Algorithm by using simple window selection practices. Submitted. http://fviveros.gelbukh.com/wordnet.html} , la cual es una API de WordNet en Java que permite, que las aplicaciones desarrolladas en Java principalmente recuperen datos de WordNet\footnote{WordNet. http://wordnet.princeton.edu/} 3.0.

En este trabajo se utiliza la lematizaci\'on sint\'actica, teniendo en cuenta el contexto de las palabras de una oraci\'on y desambiguando cada una de ellas.  Para este tipo de lematizaci\'on fue necesario tambi\'en realizar un an\'alisis sint\'actico a trav\'es de un etiquetador de palabras\footnote{El core de Stanford incluye c\'odigo dedicado a la  tokenizaci\'on, parsing, etiquetado de partes del discurso entre otras. http://nlp.stanford.edu/software/index.shtml}  incluido en la suite de herramientas de an\'alisis para el procesamiento del lenguaje natural para el idioma Ingl\'es creado por el grupo de Procesamiento de Lenguaje Natural de la Universidad de Stanford\footnote{Descarga de la Suite. http://nlp.stanford.edu/}. Esta herramienta tiene como objetivo, a partir de una oraci\'on o palabra, identificar partes de texto como sustantivo, verbo y adjetivo. El etiquetador utilizado para analizar el texto, el cual se encuentra en idioma Ingl\'es,  utiliza el conjunto de etiquetas Penn Treebank\footnote{Etiquetas Penn Treebank.\\ https://www.ling.upenn.edu/courses/Fall\_2003/ling001/penn\_treebank\_pos.html}.


\section{Sistemas de extracci\'on abierta}
La extracci\'on abierta de Informaci\'on, es una tarea que, sin requerir vocabulario especificado previamente, permite la extracci\'on de sentencias de corpus masivos.
Generalmente y sin escalar grandes corpus donde se encuentra gran cantidad de relaciones o las mismas no pueden ser anticipadas, los sistemas de extracci\'on de informaci\'on aprenden un extractor para cada relaci\'on desde ejemplos de entrenamiento etiquetados ~\cite{KimMol:93}.

Luego este problema fue resuelto por estos sistemas a trav\'es de la identificaci\'on de frases de relaciones (frases que denotan relaciones a partir de sentencias en Ingl\'es). La identificaci\'on autom\'atica de las mismas,	 en conjunto con la restricci\'on de obviar un vocabulario anticipado, permite la extracci\'on arbitraria  de relaciones a partir de sentencias en el idioma Ingl\'es
~\cite{BanCafSodBroEtz:07}.

Los primeros sistemas de Extracci\'on de informaci\'on abierta como TextRunner ~\cite{EtBaSoWe:12}, WOEpos, and WOEparse ~\cite{WuWe:10} utilizaban los siguientes pasos:
\begin{itemize}
\item	\emph{Etiquetar:} las oraciones se etiquetaban autom\'aticamente con extracciones usando heur\'isticas. La cantidad de ejemplos necesarios rondaba aproximadamente 200.000 sentencias para TextRunner y 300.000 para WOE.
\item	\emph{Aprender:} un extractor de frase de relaci\'on aprend\'ia mediante un modelo gr\'afico de etiquetado secuencial (CRF\footnote{Modelo gr\'afico de etiquetado secuencial. \\ http://es.wikipedia.org/wiki/Campo\_aleatorio\_condicional}), con el costo de un entrenamiento demasiado caro.
\item	\emph{Extracci\'on:} el sistema tomaba una frase como entrada, identificaba pares de sustantivos de una oraci\'on, y luego usaba el extractor aprendido para etiquetar cada palabra entre los dos argumentos como parte de la relaci\'on.
\end{itemize}

En este trabajo se utiliz\'o ReVerb como herramienta para la extracci\'on abierta, siendo esta destacada por diferentes entidades por su facilidad de uso, instalaci\'on, manejo y eficiencia.
ReVerb es un sistema que identifica y extrae autom\'aticamente relaciones a partir de oraciones en idioma Ingl\'es. Gracias a su diseño, permite la extracci\'on a gran escala donde la velocidad es importante y la generaci\'on de una salida en forma de triupla entre otros datos (Argumento 1(Agente), relaci\'on, argumento 2(objeto)) es f\'acilmente manejable.

Generalmente ReVerb es comparado con los siguientes sistemas:
\begin{itemize}
\item	\emph{TextRunner:} extractor de Banko y Etzioni, uno de los primeros extractores construidos. Año 2008.
\item	\emph{TextRunner-R:} representa la versi\'on b\'asica de TextRunner que usa el modelo de relaci\'on computado por ReVerb.
\item	\emph{WOEpos:} versi\'on de TextRunner que usa la relaci\'on aprendida de Wikipedia por una heur\'istica, desarrollado por Wu y Weld en el año 2010.
\item	\emph{WOEparse:} extractor de Wu y Weld basado en parser, utilizando un gran conjunto de dependencias basada en extracci\'on de patrones.
\item	\emph{ReVerb-Lex:} corresponde a la versi\'on de ReVerb sin las restricciones l\'exicas.
\end{itemize}

ReVerb, como m\'etodo para encontrar las relaciones, en primer lugar, identifica las relaciones que satisfacen las restricciones l\'exicas y sint\'acticas y luego, en base a este dato, busca un par de argumentos para cada una de las relaciones encontradas. A esta extracci\'on, le asigna un puntaje de confianza, llamado nivel de confianza\footnote{Niveles de confianza. http://homes.cs.washington.edu/~afader/bib\_pdf/emnlp11.pdf}, usando un clasificador de regresi\'on l\'ogica\footnote{Clasificador de regresi\'on L\'ogica. \\ http://ocw.uv.es/ingenieria-y-arquitectura/2/classificacio.pdf}. Este mecanismo, ser\'a descrito en el algoritmo ~\ref{alg1} de extracci\'on usado por ReVerb.

\begin{algorithm}
\caption{Algoritmo de extracci\'on utilizado por Reverb}
\label{alg1}
\begin{algorithmic}
    \REQUIRE texto plano dividido en sentencias.
    \ENSURE conjunto de relaciones (\emph{x},\emph{r},\emph{z})
    \WHILE{exista sentencia \emph{S}}
            \STATE Extracci\'on de la relaci\'on: encontrar la secuencia m\'as larga de palabras \emph{Rv}
	    \WHILE{exista verbo \emph{v} en \emph{S}}		
	            \STATE \emph{Rv} comienza en \emph{v}
		 \STATE \emph{Rv} satisface las restricciones sint\'acticas
	            \STATE \emph{Rv} satisface las restricciones l\'exicas.\\
	            \STATE Si un par de coincidencias son adyacentes o se superponen, unirlas.\\
	    \ENDWHILE

	 \STATE Extracci\'on de los argumentos
	    \WHILE{exista una relaci\'on extra\'ida \emph{r}}
	            \STATE Argumento1 (izquierda): busca el fragmento sustantivo m\'as cercano a la izquierda de \emph{r} que no es un pronombre relativo, ni adverbio \emph{Who}, ni existencial \emph{All\'i}.
		 \STATE Argumento de la derecha: encuentra la frase sustantiva \emph{z} m\'as cercana a la derecha de \emph{r} en \emph{S}.
	    \ENDWHILE
    \ENDWHILE

    \STATE Retorna la triupla (\emph{x}, \emph{r}, \emph{z}) encontrada como relaci\'on
\end{algorithmic}
\end{algorithm}

La validaci\'on de las restricciones l\'exicas para chequear si \emph{Rv} es v\'alido, utiliza un gran diccionario de frases de relaciones (con inflexiones, adjetivos, adverbios removidos, etc.), el cual es construido a trav\'es de la aplicaci\'on de patrones en un corpus de 500 millones de sentencias Web.

Como punto d\'ebil, ReVerb suele encontrar extracciones incoherentes, frases sin sentido o desinformativas surgidas por el manejo inapropiado de las relaciones de las frases, ya que el extractor aprendido solo toma decisiones de secuencia local.

\section{Medidas de Soporte}
Para detectar cuanta informaci\'on existe en un soporte externo \emph{E${_s}$} que contribuye a demostrar que la informaci\'on es ver\'idica, importante, bien conocida o todas ellas juntas, centramos nuestro objetivo en definir una medida que estima el soporte externo de un documento \textit{d}. Para alcanzar dicho objetivo, tomamos como base (lo mismo que en ~\cite{LeVoErFeCaHoGrr:12}) el conjunto de hechos \emph{F${_d}$}, que corresponde a la colecci\'on de hechos extra\'idos de un documento  \textit{d}, a trav\'es de un m\'etodo \emph{IE} (Extractor de informaci\'on).
Mirando particularmente cada hecho \emph{f${_i}$ $\in$ F${_d}$} y estimando el soporte externo s${_e}$(f${_i}$) que este hecho tiene en la \emph{FE} \emph{E${_s}$}, podemos definir el soporte externo S${_e}$(d) de un documento completo \textit{d} como la suma de pesos del soporte s${_e}$(f${_i}$) de cada \emph{f${_i}$ $\in$ F${_d}$}.

Esta \'ultima idea podemos plasmarla formalmente en notaci\'on matem\'atica en la siguiente definici\'on.\\

\textbf{Definici\'on 5}: Sea \emph{d} un documento y F${_d}$ = \{\textit{f1}. . . \textit{fn}\} la colecci\'on de hechos extra\'idos de \emph{d} por un m\'etodo de extracci\'on arbitrario \emph{(IE)}. El soporte factual externo de \textit{d}, denotado \emph{S${_e}$}(\emph{d}), lo definimos de la siguiente manera:\\

\begin{equation}
 \label{eq:ec1}
S{_e}(d) =  \sum_{i=1}^{n}w_{i} s_{e}(f_{i})
\end{equation}

Donde \emph{w${_i}$} es el peso que el hecho posee en el documento \textit{d} y \emph{s${_e}$(f${_i}$)} es el soporte factual externo de \emph{f${_i}$}.
La utilizaci\'on de los pesos \emph{w${_i}$} y soporte externo, radica en que muchas veces no todos hechos poseen la misma importancia en el documento evaluado. Por ejemplo, en ~\cite{MaWa:10} los hechos obtenidos de sentencias que aparecen al principio del documento, son tomadas como de mayor importancia.

En este trabajo no tomaremos en cuenta la informaci\'on posicional para determinar la importancia de los hechos, sino que utilizaremos directamente los valores entregados por ReVerb conocido como nivel de confianza.
El nivel de confianza, asociado a cada hecho particular de un documento \textit{d}, denotado como c${_i}$, denota cuan confiado est\'a el extractor de que su extracci\'on \emph{f${_i}$} es precisa.

Para determinar \emph{W${_i}$}, podemos tomar uniformemente el valor 1 para cualquier \emph{w${_i}$}, o tomar \emph{c${_i}$} = \emph{w${_i}$}. Sin embargo, otra alternativa ser\'ia considerar solamente \emph{c${_i}$} = \emph{w${_i}$} solo cuando se supere cierto umbral \emph{t}. Fijando el umbral \emph{t} =  0.8 	consideramos el siguiente valor para \emph{w${_i}$}:

\begin{equation}
 \label{eq:ec2}
     w{_i} = \left\{
	       \begin{array}{ll}
		 c{_i}      & \mathrm{si\ } c{_i} \geq 0.8 \\
		 0 & \mathrm{si\ } c{_i} < 0.8 		
	       \end{array}
	     \right.
\end{equation}

Otro valor fundamental que calcular para computar \emph{S${_e}$(d)} es el soporte factual externo de \emph{f${_i}$}, llamado \emph{s${_e}$(f${_i}$)}. Intuitivamente, este valor representa la cantidad de veces que el hecho \emph{f${_i}$} fue encontrado en la \emph{FE} \emph{E${_s}$}. Por lo cual, si el hecho \emph{f${_i}$} aparece \emph{N${_i}$} veces en \emph{E${_s}$}, definimos como soporte factual externo \emph{S${_e}$(f${_i}$) = N${_i}$}. Sin embargo, tambi\'en podemos estar interesados en el caso booleano, es decir, si el hecho \emph{f${_i}$} fue encontrado o no en la \emph{FE}. En este caso definimos \emph{S${_e}$(f${_i}$)} como:

\begin{equation}
     \label{eq:ec3}
     s{_e}f{_i} = \left\{
	       \begin{array}{ll}
		 1 & \mathrm{si\ } f{_i} \in E{_s} \\
		 0 & otro \ caso 		
	       \end{array}
	     \right.
\end{equation}

Otro detalle a tener en cuenta en el c\'alculo del soporte es el tamaño de un documento \textit{d}, permiti\'endonos definir alg\'un tipo de normalizaci\'on directa que nos permita relacionar el resultado obtenido con los diferentes tamaños de los documentos evaluados. Por lo cual, en lugar de usar directamente la f\'ormula definida en la ecuaci\'on ~\ref{eq:ec1}, utilizaremos una f\'ormula m\'as general que nos permita definir diferentes tipos de normalizaciones. Entonces, la f\'ormula final para el \emph{soporte factual externo} por un documento queda plasmado de la siguiente manera:

\begin{equation}
\label{eq:ec4}
S{_e}'(d) = \frac {S{_e}(d)} {\emph{n${_o}$${_r}$}}
\end{equation}

Con el factor de normalizaci\'on \emph{n${_o}$${_r}$} tomando uno de los siguientes valores:
\begin{itemize}
\item \emph{n${_o}$${_r}$} = 1 (Sin normalizaci\'on).
\item \emph{n${_o}$${_r}$} = \emph{NL${_d}$} (cantidad de l\'ineas en \emph{d}).
\item \emph{n${_o}$${_r}$} = \emph{NW${_d}$} (cantidad de palabras en \emph{d}).
\item \emph{n${_o}$${_r}$} = \emph{|F${_d}$|} (cantidad de hechos extra\'idos desde \emph{d}).\\
\end{itemize}

Las alternativas para \emph{w${_i}$} son las siguientes:
\begin{itemize}
\item	\emph{C} cuando \emph{w${_i}$ = c${_i}$}.
\item	\emph{T} cuando la ecuaci\'on ~\ref{eq:ec2} es utilizada.
\item	\emph{U} cuando \emph{w${_i}$ = 1}. \\
\end{itemize}

Las alternativas para \emph{s${_e}$(f${_i}$)} se definen de la siguiente manera:
\begin{itemize}
\item	\emph{N} cuando \emph{se(f${_i}$) = N${_i}$}
\item	\emph{B} para el caso booleano (Ecuaci\'on ~\ref{eq:ec3}) \\
\end{itemize}

Las alternativas para la normalizaci\'on son las siguientes:
\begin{itemize}
\item	\emph{N} (Sin normalizaci\'on)
\item   \emph{L} (Normalizaci\'on basada en la cantidad de l\'ineas)
\item	\emph{W} (Normalizaci\'on basada en la cantidad de palabras)
\item	\emph{F} (Normalizaci\'on basada en la cantidad de hechos) \\
\end{itemize}

Para realizar el c\'alculo del soporte factual externo, utilizamos diferentes m\'etodos que surgen de las diferentes combinaciones del peso \emph{(w${_i}$)}, el soporte externo de los hechos \emph{(s${_e}$(f${_i}$))} y el uso de la normalizaci\'on.

Siguiendo la convenci\'on utilizada arriba, al anexar cada letra, se formar\'a un c\'odigo que identificar\'a un\'ivocamente la medida de soporte.
Entonces, por ejemplo, el soporte factual externo identificado como “CNW”, corresponder\'a al caso en el que \emph{w${_i}$} es el nivel de confianza asignado por el sistema de extracci\'on de hechos (ReVerb en nuestro caso) a \emph{f${_i}$}, el soporte externo de \emph{f${_i}$} es el n\'umero de ocurrencias de \emph{f${_i}$} en \emph{E${_s}$} y los resultados son normalizados teniendo en cuenta el n\'umero de palabras en cada documento \emph{d}. El  cuadro ~\ref{table:tablacod1} resume las codificaciones de soporte que resultan de las diferentes combinaciones de \emph{W${_i}$, s${_e}$(f${_i}$), N${_o}$${_r}$}.	

\begin{table}
  \centering
  \renewcommand{\arraystretch}{1.3}
   \begin{tabular}{ l l l l }
    \hline
     & & \\
   \textbf{Codificaci\'on} & \textbf{\emph{w${_i}$}} & \textbf{\emph{s${_e}$(f${_i}$)}} & \textbf{\emph{N${_o}$${_r}$}} \\ \\
   \hline
    & & \\
   CBF & \emph{c${_i}$} & Ecuaci\'on ~\ref{eq:ec3} & \emph{|F${_d}$|} \\
   CBL & \emph{c${_i}$} & Ecuaci\'on ~\ref{eq:ec3} & \emph{NL${_d}$} \\
   CBN & \emph{c${_i}$} & Ecuaci\'on ~\ref{eq:ec3} & 1 \\
   CBW & \emph{c${_i}$} & Ecuaci\'on ~\ref{eq:ec3} & \emph{NW${_d}$} \\
   CNF & \emph{c${_i}$} & \emph{N${_i}$} & \emph{|F${_d}$|} \\
   CNL & \emph{c${_i}$} & \emph{N${_i}$} & \emph{NL${_d}$} \\
   CNN & \emph{c${_i}$} & \emph{N${_i}$} & 1 \\
   CNW & \emph{c${_i}$} & \emph{N${_i}$} & \emph{NW${_d}$} \\
   TBF & Ecuaci\'on ~\ref{eq:ec2} & Ecuaci\'on ~\ref{eq:ec3} & \emph{|F${_d}$|} \\
   TBL & Ecuaci\'on ~\ref{eq:ec2} & Ecuaci\'on ~\ref{eq:ec3} & \emph{NL${_d}$} \\
   TBN & Ecuaci\'on ~\ref{eq:ec2} & Ecuaci\'on ~\ref{eq:ec3} & 1 \\
   TBW & Ecuaci\'on ~\ref{eq:ec2} & Ecuaci\'on ~\ref{eq:ec3} & \emph{NW${_d}$} \\
   TNF & Ecuaci\'on ~\ref{eq:ec2} & \emph{N${_i}$} & \emph{|F${_d}$|} \\
   TNL & Ecuaci\'on ~\ref{eq:ec2} & \emph{N${_i}$} & \emph{NL${_d}$} \\
   TNW & Ecuaci\'on ~\ref{eq:ec2} & \emph{N${_i}$} & \emph{NW${_d}$} \\
   TNN & Ecuaci\'on ~\ref{eq:ec2} & \emph{N${_i}$} & 1 \\
   UBF & 1 & Ecuaci\'on ~\ref{eq:ec3} & \emph{|F${_d}$|} \\
   UBL & 1 & Ecuaci\'on ~\ref{eq:ec3} & \emph{NL${_d}$} \\
   UBN & 1 & Ecuaci\'on ~\ref{eq:ec3} & 1 \\
   UBW & 1 & Ecuaci\'on ~\ref{eq:ec3} & \emph{NW${_d}$} \\
   UNF & 1 & \emph{N${_i}$} & \emph{|F${_d}$|} \\
   UNL & 1& \emph{N${_i}$} & \emph{NL${_d}$} \\
   UNN & 1 & \emph{N${_i}$} & 1 \\
   UNW & 1 & \emph{N${_i}$} & \emph{NW${_d}$} \\
   \hline
   \end{tabular}
\caption {Codificaciones del soporte factual externo.}
\label{table:tablacod1}
\end{table}


\section{Mecanismos de Matching}
Para detectar si un hecho \emph{f${_i}$} de un documento \emph{d} que contiene hechos, tiene soporte en la \emph{FE}, se utilizan diferentes mecanismos dependiendo si se busca que el matching sea estricto o relajado.
Para ambos casos, en primer lugar, se extrae un registro completo de los AH y se separan los argumentos, la relaci\'on y el nivel de confianza que este posea. Luego, se comienza a recorrer la \emph{FE} obteniendo cada uno de los registros de la misma separando tambi\'en los argumentos, la relaci\'on y el nivel de confianza.

La \emph{FE} se recorre desde el primer hasta el \'ultimo registro tomando en cada instancia la fila completa en cualquiera de las versiones para todo hecho buscado.

En el caso de la versi\'on con \emph{matching estricto}, ya con todos los datos extra\'idos y disponibles, solo se compara si cada uno de los argumentos y la relaci\'on coincide con los argumentos y la relaci\'on del hecho de la \emph{FE}. Si alguno de ellos no coincide, se toma un nuevo registro en la \emph{FE}, mientras que si todos coinciden  se realiza el c\'alculo de todas las medidas correspondientes.
Este procedimiento se completa cuando se revisaron todos los hechos encontrados en el documento \emph{d} de AH y fueron comparados contra todos los hechos de la FE.

En el caso de las \emph{versiones relajadas} (Matching local y Global), se utiliza el \emph{Índice de Jaccard} para medir el grado de similitud entre los argumentos y las relaciones.

El \'indice de Jaccard, tambi\'en conocido como coeficiente de similitud Jaccard, es utilizado para medir la similitud entre dos conjuntos finitos de datos. Informalmente podemos definir el \'indice como el tamaño de la intersecci\'on dividido el tamaño de de la uni\'on del conjunto de datos. Formalmente lo definimos en la ecuaci\'on ~\ref{eq:jaccard} de la siguiente manera:

\begin{equation}
	\label{eq:jaccard}
           Jac(A,B) = \frac {A \cap B} {A \cup B}
\end{equation}

Para la \emph{versi\'on local}, este \'indice es calculado para cada uno de los argumentos as\'i tambi\'en como para la relaci\'on de manera separada, mientras que para la \emph{versi\'on global}, el \'indice se calcula comparando hechos completos sin diferenciar ninguno de los argumentos.

Tambi\'en se fija un umbral para filtrar solo aquellos hechos que obtuvieron un valor Jaccard mayor igual a 0.5 en la versi\'on local y mayor a 0.1 en la versi\'on global, eliminando as\'i hechos que produzcan poca informaci\'on o tengan bajo nivel de similitud.

A continuaci\'on mostramos formalmente las ecuaciones para la versi\'on local y global respectivamente de matching relajado.

\begin{equation}
	\label{eq:jaccard1}
           M{_l}(f{_i}; f{_e}) = Jac(s{_i}{_1} ; s{_e}{_1} ) X Jac(s{_i}{_2} ; s{_e}{_2} ) X Jac(s{_i}{_3} ; s{_e}{_3})
\end{equation}

\begin{equation}
	\label{eq:jaccard2}
           M{_l}(f{_i}; f{_e}) = Jac (s{_i}{_1} \cup s{_i}{_2} \cup s{_i}{_3}, s{_e}{_1} \cup s{_e}{_2} \cup s{_e}{_3})
\end{equation} 